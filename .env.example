# Context-Generator MCP Server Environment Configuration

# ================================
# OPENAI CONFIGURATION
# ================================
# OpenAI API for enhanced content extraction and processing
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-3.5-turbo

# ================================ 
# OLLAMA CONFIGURATION
# ================================
# Ollama for local AI processing (no API key required for local instances)
# 
# REQUIRED: Model name - see available models with: ollama list
# Popular models: llama3.1, llama3, codellama, mistral, phi3
# OLLAMA_MODEL=llama3.1
#
# OPTIONAL: Custom Ollama base URL (default: http://localhost:11434)
# Use this for remote Ollama instances or custom ports
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_BASE_URL=http://your-remote-ollama-server:11434
#
# OPTIONAL: API key for hosted Ollama instances (most local instances don't need this)
# OLLAMA_API_KEY=your_ollama_api_key_here

# ================================
# SETUP INSTRUCTIONS
# ================================
# 1. Install Ollama: https://ollama.com/download
# 2. Pull a model: ollama pull llama3.1
# 3. Start Ollama: ollama serve (if not auto-started)
# 4. Set OLLAMA_MODEL above to your chosen model
# 5. Optionally set OLLAMA_BASE_URL if using custom host/port

# ================================
# CRAWLER CONFIGURATION
# ================================
# Default crawling behavior settings
# DEFAULT_MAX_PAGES=50
# DEFAULT_MAX_DEPTH=3
# DEFAULT_DELAY_MS=1000

# ================================
# FILE OUTPUT CONFIGURATION
# ================================  
# Default output directory for generated context files
# DEFAULT_OUTPUT_DIR=./output

# ================================
# DEBUG & LOGGING
# ================================
# Set to 'true' to enable verbose logging (development only)
# DEBUG_CRAWLER=false
# DEBUG_AI=false

# Note: All environment variables are optional.
# The server will work without them, but AI-enhanced features require either OpenAI or Ollama configuration.
