# üöÄ context-generator MCP Server

An MCP (Model Context Protocol) server that scrapes documentation websites and generates `context` files. Built with proven x-crawl patterns for reliable web scraping.

## ‚ú® Features

- üï∑Ô∏è **Smart Documentation Crawling** - Uses x-crawl with documentation-specific enhancements
- üß† **Platform Detection** - Automatically detects GitBook, Docusaurus, VuePress, and other platforms
- üìù **Clean Content Extraction** - Removes navigation, ads, and preserves formatting
- üìã **context Generation** - Creates both `llms.txt` and `llms-full.txt` formats
- ‚ö° **MCP Integration** - Works seamlessly with any MCP client
- ü¶ô **Local AI Processing** - Full Ollama integration for privacy-focused AI features
- üíæ **Robust File Operations** - Enterprise-grade file writing with comprehensive error handling
- üîß **Enhanced Tool Descriptions** - LLM-optimized tool schemas with detailed usage guidance

## üõ†Ô∏è MCP Tools

### `scrape_documentation`
Scrape an entire documentation website and extract content.

```json
{
  "url": "https://docs.example.com",
  "options": {
    "maxPages": 50,
    "maxDepth": 3,
    "outputFormat": "both",
    "delayMs": 1000
  }
}
```

### `preview_page`
Preview content extraction from a single page.

```json
{
  "url": "https://docs.example.com/getting-started"
}
```

### `detect_platform`
Detect the documentation platform type for optimization.

```json
{
  "url": "https://docs.example.com"
}
```

### `generate_context`
Generate context format from crawled content.

```json
{
  "crawlResults": [...],
  "options": {
    "format": "full",
    "includeSourceUrls": true
  }
}
```

## üîß Installation

```bash
npm install
npm run build
```

## üèÉ‚Äç‚ôÇÔ∏è Running

```bash
npm start
```

## üß™ Development

```bash
npm run dev
```

## üìñ Usage with MCP Clients

### Basic Configuration

Add to your MCP client configuration:

```json
{
  "context-generator": {
    "command": "node",
    "args": ["/path/to/context-generator-server/dist/index.js"]
  }
}
```

### ü§ñ AI Integration (Optional)

For enhanced crawling and content processing, you can configure AI providers.

#### ü¶ô Ollama (Recommended for Local Use)

**Benefits:**
- üîí **Privacy**: All data stays on your machine
- üí∞ **Cost-effective**: No API fees
- ‚ö° **Fast**: Local processing
- üåê **Offline**: Works without internet

**Quick Setup:**
```bash
# 1. Install Ollama: https://ollama.com/download
# 2. Pull a model
ollama pull llama3.1

# 3. Configure environment
echo "OLLAMA_MODEL=llama3.1" >> .env

# 4. Test the integration
npm run test:ollama
```

**MCP Configuration:**
```json
{
  "context-generator": {
    "command": "node",
    "args": ["/path/to/context-generator-server/dist/index.js"],
    "env": {
      "OLLAMA_MODEL": "llama3.1"
    }
  }
}
```

#### üîë OpenAI (Cloud-based)

**Benefits:**
- üöÄ **Powerful**: Latest GPT models
- ‚òÅÔ∏è **No setup**: Cloud-based processing
- üîß **Maintenance-free**: Always updated

**Setup:**
```json
{
  "context-generator": {
    "command": "node",
    "args": ["/path/to/context-generator-server/dist/index.js"],
    "env": {
      "OPENAI_API_KEY": "sk-your-openai-key",
      "OPENAI_MODEL": "gpt-4"
    }
  }
}
```

#### üîó Mixed Configuration

```json
{
  "context-generator": {
    "command": "node",
    "args": ["/path/to/context-generator-server/dist/index.js"],
    "env": {
      "OPENAI_API_KEY": "sk-your-openai-key",
      "OPENAI_MODEL": "gpt-4",
      "OLLAMA_MODEL": "llama3.1",
      "OLLAMA_BASE_URL": "http://localhost:11434"
    }
  }
}
```

#### Environment Variables Reference

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| **OpenAI** |
| `OPENAI_API_KEY` | OpenAI API key for AI-assisted crawling | - | ‚úÖ (for OpenAI) |
| `OPENAI_MODEL` | OpenAI model to use | `gpt-3.5-turbo` | ‚ùå |
| **Ollama** |
| `OLLAMA_MODEL` | Ollama model name (e.g., `llama3.1`, `codellama`) | `llama3.1` | ‚úÖ (for Ollama) |
| `OLLAMA_BASE_URL` | Custom Ollama server URL | `http://localhost:11434` | ‚ùå |
| `OLLAMA_API_KEY` | API key for hosted Ollama instances | - | ‚ùå |

> **üìñ Detailed Setup:** See [OLLAMA_SETUP.md](./OLLAMA_SETUP.md) for complete installation and configuration instructions.

> **üß™ Testing:** Use `npm run test:ollama` to validate your Ollama setup.

> **‚ö†Ô∏è Note:** AI integration is optional. The server works without these variables, but AI-enhanced features won't be available.
